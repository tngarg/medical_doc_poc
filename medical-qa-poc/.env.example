# Environment variables for the Medical QA PoC project

# Hugging Face Hub API Token (if using models from the Hub)
HUGGINGFACEHUB_API_TOKEN="your_huggingface_api_token_here"

# Example for another API key (e.g., a specific LLM provider)
# ANOTHER_PROVIDER_API_KEY="your_other_provider_api_key_here"

# Flask specific (optional, Flask defaults are often fine for development)
FLASK_APP="app.py"
FLASK_ENV="development" # or "production"
# FLASK_RUN_PORT=5000
# FLASK_DEBUG=True

# Path to data directory (can be relative or absolute)
DATA_PATH="./data"

# Vector Store Configuration
VECTOR_STORE_TYPE="faiss" # e.g., "faiss", "chroma"
PERSIST_DIRECTORY="./vector_store_db"

# Knowledge Graph Configuration
KG_FILE_PATH="./data/medical_kg.gml"

# LLM Model Configuration (example)
# MODEL_NAME="sentence-transformers/all-MiniLM-L6-v2" # for embeddings
# QA_MODEL_NAME="google/flan-t5-base" # for question answering
QA_MODEL_PROVIDER="huggingface" # e.g., "huggingface", "openai"

# Logging Level
LOG_LEVEL="INFO" # DEBUG, INFO, WARNING, ERROR, CRITICAL
