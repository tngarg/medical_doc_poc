{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical QA System: Experimentation and Evaluation Notebook\n",
    "\n",
    "This notebook is designed for developing, testing, and evaluating components of the Medical QA system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration\n",
    "\n",
    "- Load environment variables.\n",
    "- Import necessary libraries and project modules.\n",
    "- Configure paths and model names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext autoreload\n",
    "# %autoreload 2\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv(override=True) # Use override=True if you need to reload during notebook execution\n",
    "\n",
    "# Add project root to Python path (if modules are not found)\n",
    "# import sys\n",
    "# sys.path.append(os.path.abspath('..')) # Adjust based on notebook location relative to project root\n",
    "\n",
    "# Import your project modules\n",
    "# from document_loader import DocumentLoader\n",
    "# from vector_store import VectorStoreManager\n",
    "# from knowledge_graph import KnowledgeGraphManager\n",
    "# from agents import SimpleVectorStoreAgent, KnowledgeGraphAgent # ... and other agents\n",
    "# from mcp import MasterControlProgram\n",
    "# from fallback import FallbackHandler\n",
    "\n",
    "print(f\"DATA_PATH: {os.getenv('DATA_PATH')}\")\n",
    "print(f\"PERSIST_DIRECTORY (Vector Store): {os.getenv('PERSIST_DIRECTORY')}\")\n",
    "print(f\"KG_FILE_PATH: {os.getenv('KG_FILE_PATH')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Loading and Preprocessing\n",
    "\n",
    "- Initialize `DocumentLoader`.\n",
    "- Load documents from the `DATA_PATH`.\n",
    "- Experiment with chunking strategies and text splitting parameters.\n",
    "- Inspect loaded and split documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA_DIR = os.getenv(\"DATA_PATH\", \"./data\") # Default to ./data if not set\n",
    "# doc_loader = DocumentLoader(data_path=DATA_DIR, chunk_size=1000, chunk_overlap=150)\n",
    "\n",
    "# # Load and split documents\n",
    "# processed_documents = doc_loader.load_and_split_documents()\n",
    "\n",
    "# if processed_documents:\n",
    "#     print(f\"Loaded and split {len(processed_documents)} document chunks.\")\n",
    "#     print(\"Example chunk metadata:\", processed_documents[0].metadata)\n",
    "#     print(\"Example chunk content snippet:\", processed_documents[0].page_content[:200])\n",
    "# else:\n",
    "#     print(\"No documents processed. Check DATA_PATH.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vector Store Management\n",
    "\n",
    "- Initialize `VectorStoreManager`.\n",
    "- Create or load a vector store using the processed documents.\n",
    "- Test similarity search with sample queries.\n",
    "- Evaluate different embedding models (if applicable)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# EMBEDDING_MODEL_NAME = os.getenv(\"MODEL_NAME\", \"sentence-transformers/all-MiniLM-L6-v2\")\n",
    "# VECTOR_DB_PATH = os.getenv(\"PERSIST_DIRECTORY\", \"./vector_store_db\")\n",
    "\n",
    "# vs_manager = VectorStoreManager(persist_directory=VECTOR_DB_PATH, embedding_model_name=EMBEDDING_MODEL_NAME)\n",
    "\n",
    "# # Create/load the store (force_recreate=True for initial setup or changes)\n",
    "# # Ensure 'processed_documents' is available from the previous step\n",
    "# if 'processed_documents' in locals() and processed_documents:\n",
    "#     vector_db = vs_manager.create_or_load_store(documents=processed_documents, force_recreate=True)\n",
    "#     if vector_db:\n",
    "#         print(\"Vector store created/loaded successfully.\")\n",
    "#     else:\n",
    "#         print(\"Failed to create/load vector store.\")\n",
    "# else:\n",
    "#     print(\"Skipping vector store creation as no documents were processed.\")\n",
    "\n",
    "# # Test search\n",
    "# if vs_manager.vector_store:\n",
    "#     sample_query = \"What are the treatments for diabetes?\"\n",
    "#     search_results = vs_manager.similarity_search(query=sample_query, k=3)\n",
    "#     print(f\"\\nSearch results for '{sample_query}':\")\n",
    "#     for doc, score in search_results:\n",
    "#         print(f\"  Source: {doc.metadata.get('source', 'N/A')}, Score: {score:.4f}, Content: {doc.page_content[:100]}...\")\n",
    "# else:\n",
    "#     print(\"Vector store not available for search test.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Knowledge Graph Construction and Querying\n",
    "\n",
    "- Initialize `KnowledgeGraphManager`.\n",
    "- Develop methods/scripts to extract entities and relationships from documents (this is a major sub-task, potentially using NLP/LLMs).\n",
    "- Add extracted triplets to the KG.\n",
    "- Test KG querying with sample questions/entities.\n",
    "- Visualize the KG."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KG_PATH = os.getenv(\"KG_FILE_PATH\", \"./data/medical_kg.gml\")\n",
    "# kg_manager = KnowledgeGraphManager(kg_file_path=KG_PATH)\n",
    "\n",
    "# # Example: Manually adding some triplets\n",
    "# # In a real scenario, these would be extracted from documents or other sources\n",
    "# example_triplets = [\n",
    "#     (\"Aspirin\", \"Drug\", \"treats\", \"Headache\", \"Symptom\"),\n",
    "#     (\"Aspirin\", \"Drug\", \"may_cause\", \"Bleeding\", \"SideEffect\"),\n",
    "#     (\"Diabetes\", \"Condition\", \"associated_with\", \"HighBloodSugar\", \"Finding\")\n",
    "# ]\n",
    "# kg_manager.add_triplets(example_triplets)\n",
    "# kg_manager.save_graph()\n",
    "# print(f\"KG has {kg_manager.graph.number_of_nodes()} nodes and {kg_manager.graph.number_of_edges()} edges.\")\n",
    "\n",
    "# # Test query\n",
    "# if kg_manager.graph.number_of_nodes() > 0:\n",
    "#     query_results = kg_manager.query_graph(start_node=\"Aspirin\", relationship=\"treats\")\n",
    "#     print(f\"\\nQuery: What does Aspirin treat? Result: {query_results}\")\n",
    "# else:\n",
    "#     print(\"KG is empty, skipping query test.\")\n",
    "\n",
    "# # Visualize (requires matplotlib and a display environment or saves to file)\n",
    "# # kg_manager.visualize_graph(output_file='./data/kg_notebook_visualization.png')\n",
    "# # print(\"KG visualization saved if graph was not empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agent Initialization and Testing\n",
    "\n",
    "- Initialize individual agents (e.g., `SimpleVectorStoreAgent`, `KnowledgeGraphAgent`).\n",
    "- This may involve loading LLMs, configuring API keys (already in .env).\n",
    "- Test each agent with sample questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Ensure VectorStoreManager (vs_manager) and KnowledgeGraphManager (kg_manager) are initialized\n",
    "# \n",
    "# # Initialize LLM (example, replace with your actual LLM setup)\n",
    "# # from langchain.llms import HuggingFaceHub # or other LLM providers\n",
    "# # from langchain.chains import RetrievalQA\n",
    "# # HUGGINGFACEHUB_API_TOKEN = os.getenv(\"HUGGINGFACEHUB_API_TOKEN\")\n",
    "# # if HUGGINGFACEHUB_API_TOKEN:\n",
    "# #     llm = HuggingFaceHub(repo_id=\"google/flan-t5-small\", model_kwargs={\"temperature\":0.7, \"max_length\":256}, huggingfacehub_api_token=HUGGINGFACEHUB_API_TOKEN)\n",
    "# # else:\n",
    "# #     llm = None\n",
    "# #     print(\"Warning: HUGGINGFACEHUB_API_TOKEN not set. LLM-based agents might not work fully.\")\n",
    "\n",
    "# # Vector Store Agent\n",
    "# if 'vs_manager' in locals() and vs_manager.vector_store:\n",
    "#     # If using RetrievalQA chain, it needs a retriever from the vector store\n",
    "#     # retriever = vs_manager.vector_store.as_retriever()\n",
    "#     # qa_chain = RetrievalQA.from_chain_type(llm=llm, chain_type=\"stuff\", retriever=retriever) if llm else None\n",
    "#     # vs_agent = SimpleVectorStoreAgent(vector_store_manager=vs_manager, llm_pipeline=qa_chain)\n",
    "#     vs_agent = SimpleVectorStoreAgent(vector_store_manager=vs_manager) # Without LLM for now\n",
    "#     print(\"SimpleVectorStoreAgent initialized.\")\n",
    "#     vs_query = \"What are common side effects of Aspirin?\"\n",
    "#     vs_response = vs_agent.query(vs_query)\n",
    "#     print(f\"\\nVectorStoreAgent response for '{vs_query}':\\n{vs_response}\")\n",
    "# else:\n",
    "#     print(\"Skipping SimpleVectorStoreAgent initialization as vector store is not ready.\")\n",
    "\n",
    "# # Knowledge Graph Agent\n",
    "# if 'kg_manager' in locals() and kg_manager.graph.number_of_nodes() > 0:\n",
    "#     kg_agent = KnowledgeGraphAgent(kg_manager=kg_manager)\n",
    "#     print(\"KnowledgeGraphAgent initialized.\")\n",
    "#     kg_query = \"Aspirin\"\n",
    "#     kg_response = kg_agent.query(kg_query)\n",
    "#     print(f\"\\nKnowledgeGraphAgent response for '{kg_query}':\\n{kg_response}\")\n",
    "# else:\n",
    "#     print(\"Skipping KnowledgeGraphAgent initialization as KG is not ready or empty.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Master Control Program (MCP) Testing\n",
    "\n",
    "- Initialize `FallbackHandler`.\n",
    "- Initialize `MasterControlProgram` with the configured agents and fallback handler.\n",
    "- Test the end-to-end QA pipeline with a variety of questions.\n",
    "- Evaluate how the MCP selects answers or uses fallback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agents_list = []\n",
    "# if 'vs_agent' in locals():\n",
    "#     agents_list.append(vs_agent)\n",
    "# if 'kg_agent' in locals():\n",
    "#     agents_list.append(kg_agent)\n",
    "\n",
    "# if agents_list:\n",
    "#     fallback_h = FallbackHandler()\n",
    "#     mcp = MasterControlProgram(agents=agents_list, fallback_handler=fallback_h, confidence_threshold=0.6)\n",
    "#     print(\"MasterControlProgram initialized.\")\n",
    "\n",
    "#     test_questions = [\n",
    "#         \"What are treatments for headaches?\", # Likely VS Agent\n",
    "#         \"Tell me about Aspirin.\",             # Could be KG or VS\n",
    "#         \"What is the capital of France?\"      # Likely Fallback\n",
    "#     ]\n",
    "\n",
    "#     for q in test_questions:\n",
    "#         print(f\"\\n--- MCP Query: {q} ---\")\n",
    "#         final_answer = mcp.handle_question(q)\n",
    "#         print(f\"MCP Final Answer: {final_answer.get('answer')}\")\n",
    "#         print(f\"Chosen Agent: {final_answer.get('agent_name')}, Confidence: {final_answer.get('confidence')}\")\n",
    "# else:\n",
    "#     print(\"Skipping MCP initialization as no agents are ready.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Evaluation\n",
    "\n",
    "- Define a set of test questions with known answers/expected outcomes.\n",
    "- Run these questions through the MCP.\n",
    "- Calculate metrics (e.g., accuracy, F1 score for retrieval, answer relevance, KG query success rate).\n",
    "- Analyze failures and identify areas for improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluation_dataset = [\n",
    "#     {\"question\": \"What are the side effects of Ibuprofen?\", \"expected_keywords\": [\"nausea\", \"dizziness\"], \"expected_agent\": \"SimpleVectorStoreAgent\"},\n",
    "#     {\"question\": \"What does Paracetamol treat?\", \"expected_answer_fragment\": \"Pain\", \"expected_agent\": \"KnowledgeGraphAgent\"},\n",
    "#     # Add more test cases\n",
    "# ]\n",
    "\n",
    "# results = []\n",
    "# if 'mcp' in locals():\n",
    "#     for item in evaluation_dataset:\n",
    "#         response = mcp.handle_question(item['question'])\n",
    "#         results.append({\n",
    "#             \"question\": item['question'],\n",
    "#             \"answer\": response.get('answer'),\n",
    "#             \"agent\": response.get('agent_name'),\n",
    "#             \"confidence\": response.get('confidence'),\n",
    "#             \"expected_agent\": item.get('expected_agent'),\n",
    "#             \"expected_keywords\": item.get('expected_keywords', [])\n",
    "#         })\n",
    "#     eval_df = pd.DataFrame(results)\n",
    "#     print(\"\\nEvaluation Results:\")\n",
    "#     # display(eval_df) # Use display in a Jupyter environment\n",
    "#     print(eval_df)\n",
    "# else:\n",
    "#     print(\"MCP not initialized. Skipping evaluation.\")\n",
    "\n",
    "# # Further analysis:\n",
    "# # - Compare 'agent' with 'expected_agent'\n",
    "# # - Check if 'answer' contains 'expected_keywords'\n",
    "# # - Analyze low confidence answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Further Experiments\n",
    "\n",
    "- **Hybrid Agents**: Develop agents that combine vector search with KG lookups.\n",
    "- **Multi-turn Conversations**: Extend agents and MCP to handle follow-up questions and maintain context.\n",
    "- **LLM Fine-tuning**: Experiment with fine-tuning smaller LLMs on domain-specific medical text for better understanding and generation.\n",
    "- **Advanced KG Extraction**: Use more sophisticated NLP techniques for building the KG from text.\n",
    "- **User Feedback Loop**: Design mechanisms to incorporate user feedback for improving answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
