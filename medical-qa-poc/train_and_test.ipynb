{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Medical QA System: Training, Experimentation, and Testing Notebook
",
    "
",
    "This notebook is used to:
",
    "1. Process input documents (PDFs).
",
    "2. Create and save the FAISS vector store.
",
    "3. Create and save the Knowledge Graph.
",
    "4. Test individual components (DocumentLoader, VectorStoreManager, KnowledgeGraphManager).
",
    "5. Test agents (QueryClassifier, RAG, KG, Wikipedia).
",
    "6. Test the end-to-end MasterControlProgram (MCP)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload
",
    "%autoreload 2
",
    "
",
    "import os
",
    "import sys
",
    "from dotenv import load_dotenv
",
    "import json
",
    "
",
    "# Load environment variables from .env file
",
    "load_dotenv(override=True)
",
    "
",
    "# Add project root to Python path to allow importing modules from the parent directory
",
    "# Assuming the notebook is in medical-qa-poc/ and modules are in medical-qa-poc/
",
    "# No, if notebook is in medical-qa-poc, then direct imports should work.
",
    "# If notebook was in a subfolder like 'notebooks/', then sys.path.append('..') would be needed.
",
    "
",
    "try:
",
    "    from document_loader import DocumentLoader
",
    "    from vector_store import VectorStoreManager
",
    "    from knowledge_graph import KnowledgeGraphManager # Assuming this will be fixed
",
    "    from agents import QueryClassifierAgent, RAGAgent, KGAgent, WikipediaAgent # Assuming these are defined
",
    "    from fallback import WikipediaFallback # Assuming this is the Wikipedia searcher
",
    "    from mcp import MasterControlProgram # Assuming this is updated
",
    "except ImportError as e:
",
    "    print(f"Error importing modules: {e}. Make sure all .py files are correctly defined and paths are correct.")
",
    "    print("Some cells below might not work as expected.")
",
    "
",
    "# Configuration
",
    "DATA_DIR = os.getenv("DATA_PATH", "data/")
",
    "VECTOR_STORE_PERSIST_FOLDER = "data" # FAISS folder
",
    "VECTOR_STORE_INDEX_NAME = "vector_index" # FAISS index name (creates vector_index.faiss and vector_index.pkl)
",
    "KG_FILE_PATH = os.getenv("KG_FILE_PATH", "data/graph.pkl")
",
    "KG_VISUALIZATION_PATH = "data/kg_visualization.png"
",
    "
",
    "print(f"Data directory: {DATA_DIR}")
",
    "print(f"Vector Store will be saved in folder: '{VECTOR_STORE_PERSIST_FOLDER}' with index name: '{VECTOR_STORE_INDEX_NAME}'")
",
    "print(f"Knowledge Graph file path: {KG_FILE_PATH}")
",
    "
",
    "# Ensure data directory exists (especially for outputs like KG image)
",
    "os.makedirs(DATA_DIR, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Dummy PDF Files for Testing (if not present)
",
    "This step is optional. You should place your actual 3 medical PDFs in the `data/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pypdf import PdfWriter # Used by PyPDFLoader, so should be available
",
    "
",
    "def create_dummy_pdf(file_path, content_lines):
",
    "    if not os.path.exists(file_path):
",
    "        writer = PdfWriter()
",
    "        writer.add_blank_page(width=612, height=792) # Standard 8.5x11 inch page
",
    "        # Adding text to a PDF with pypdf is not straightforward for simple text.
",
    "        # For this dummy PDF, we'll just create a blank PDF. The content is for show.
",
    "        # Actual PDFs should have machine-readable text.
",
    "        # writer.update_page_form_field_values(writer.pages[0], {"text_field": "\n".join(content_lines)})
",
    "        with open(file_path, "wb") as f:
",
    "            writer.write(f)
",
    "        print(f"Created dummy PDF: {file_path}")
",
    "    else:
",
    "        print(f"Dummy PDF already exists: {file_path}")
",
    "
",
    "if not os.listdir(DATA_DIR) or all(not f.endswith('.pdf') for f in os.listdir(DATA_DIR)):
",
    "    print(f"No PDFs found in {DATA_DIR}, creating dummy PDFs for testing.")
",
    "    create_dummy_pdf(os.path.join(DATA_DIR, "medical_doc1.pdf"), ["Aspirin is a medication used to reduce pain, fever, or inflammation.", "Common side effects include an upset stomach."])
",
    "    create_dummy_pdf(os.path.join(DATA_DIR, "medical_doc2.pdf"), ["Diabetes mellitus is a metabolic disorder characterized by high blood sugar levels over a prolonged period.", "Symptoms often include frequent urination, increased thirst, and increased appetite."])
",
    "    create_dummy_pdf(os.path.join(DATA_DIR, "medical_doc3.pdf"), ["The knowledge graph contains information about drugs and conditions.", "Paracetamol reduces fever and alleviates pain."])
",
    "else:
",
    "    print(f"PDFs found in {DATA_DIR}. Skipping dummy PDF creation.")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Document Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:
",
    "    doc_loader = DocumentLoader(data_path=DATA_DIR, chunk_size=1000, chunk_overlap=200)
",
    "    processed_docs = doc_loader.load_and_split_documents()
",
    "
",
    "    if processed_docs:
",
    "        print(f"\nSuccessfully loaded and split {len(processed_docs)} document chunks.")
",
    "        print(f"Example of first chunk metadata: {processed_docs[0].metadata}")
",
    "        # print(f"Example of first chunk content: {processed_docs[0].page_content[:300]}...")
",
    "    else:
",
    "        print("\nNo documents were processed. Check the DATA_DIR and PDF files.")
",
    "except NameError:
",
    "    print("DocumentLoader not defined. Skipping document loading.")
",
    "    processed_docs = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Vector Store Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs_manager = None # Initialize to None
",
    "try:
",
    "    if processed_docs: # Only proceed if documents were loaded
",
    "        vs_manager = VectorStoreManager(
",
    "            persist_folder=VECTOR_STORE_PERSIST_FOLDER,
",
    "            index_name=VECTOR_STORE_INDEX_NAME
",
    "        )
",
    "        print("\nCreating/loading vector store...")
",
    "        # Use force_recreate=True to ensure fresh build for testing, set to False for incremental loads later
",
    "        vs_manager.create_or_load_store(documents=processed_docs, force_recreate=True)
",
    "
",
    "        if vs_manager.vector_store:
",
    "            print("Vector store created/loaded successfully.")
",
    "            # Test similarity search
",
    "            test_query_vs = "What are symptoms of diabetes?"
",
    "            print(f"\nTesting similarity search with query: '{test_query_vs}'")
",
    "            results = vs_manager.similarity_search(test_query_vs, k=2)
",
    "            if results:
",
    "                for doc, score in results:
",
    "                    print(f"  Source: {doc.metadata.get('source', 'N/A')}, Score (distance): {score:.4f}")
",
    "                    # print(f"    Content: {doc.page_content[:150]}...")
",
    "            else:
",
    "                print("  No results from similarity search.")
",
    "        else:
",
    "            print("\nFailed to create or load vector store.")
",
    "    else:
",
    "        print("\nNo processed documents available to create a vector store.")
",
    "except NameError:
",
    "    print("VectorStoreManager not defined. Skipping vector store creation.")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Knowledge Graph Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kg_manager = None # Initialize to None
",
    "try:
",
    "    kg_manager = KnowledgeGraphManager(kg_file_path=KG_FILE_PATH)
",
    "    # To ensure a fresh KG for testing, delete existing file if necessary
",
    "    if os.path.exists(KG_FILE_PATH):
",
    "        # print(f"Deleting existing KG file: {KG_FILE_PATH} for a fresh start...")
",
    "        # os.remove(KG_FILE_PATH)
",
    "        # kg_manager.load_graph() # Re-initialize an empty graph after deleting file
",
    "        print(f"Loading existing KG from {KG_FILE_PATH} or creating new if it fails/empty.")
",
    "
",
    "    if processed_docs: # Only extract if documents were loaded
",
    "        print("\nExtracting and adding triples to Knowledge Graph (using placeholder extractor)...")
",
    "        all_triples = []
",
    "        for i, doc_chunk in enumerate(processed_docs):
",
    "            # print(f"  Processing chunk {i+1}/{len(processed_docs)} from {doc_chunk.metadata.get('source', 'Unknown')}")
",
    "            # Limit text sent to placeholder extractor for brevity in logs
",
    "            triples = kg_manager.extract_triples_from_text(doc_chunk.page_content[:500])
",
    "            if triples:
",
    "                all_triples.extend(triples)
",
    "            if i > 5 and len(all_triples) > 3 : # Process a few chunks to get some triples for testing
",
    "                # print("  (Stopping early for KG triple extraction test)")
",
    "                # break
",
    "                pass # Process all for now
",
    "
",
    "        if all_triples:
",
    "            # The placeholder extract_triples_from_text returns dicts like {'subject':s, 'relation':p, 'object':o}
",
    "            # add_triples_data can handle this format.
",
    "            kg_manager.add_triples_data(all_triples)
",
    "            print(f"Added {len(all_triples)} potential triples to the graph.")
",
    "        else:
",
    "            print("No triples were extracted from the documents.")
",
    "    else:
",
    "        print("\nNo processed documents available to extract triples for Knowledge Graph.")
",
    "
",
    "    # Add a few manual triples for structure if none were extracted
",
    "    if kg_manager.graph.number_of_nodes() == 0:
",
    "        print("KG is empty, adding some manual example triples.")
",
    "        manual_triples = [
",
    "            {'subject': 'Aspirin', 'relation': 'treats', 'object': 'Headache', 'subject_type': 'Drug', 'object_type': 'Symptom'},
",
    "            {'subject': 'Aspirin', 'relation': 'may_cause', 'object': 'Bleeding', 'subject_type': 'Drug', 'object_type': 'SideEffect'}
",
    "        ]
",
    "        kg_manager.add_triples_data(manual_triples)
",
    "
",
    "    kg_manager.save_graph()
",
    "    print(f"Knowledge Graph saved to {KG_FILE_PATH}. Nodes: {kg_manager.graph.number_of_nodes()}, Edges: {kg_manager.graph.number_of_edges()}.")
",
    "
",
    "    # Test KG querying
",
    "    if kg_manager.graph.number_of_nodes() > 0:
",
    "        test_kg_query_entity = "Aspirin"
",
    "        print(f"\nTesting KG query for entity: '{test_kg_query_entity}' and its 'treats' relations")
",
    "        # query_graph(start_node, relationship, target_node, node_type)
",
    "        kg_results = kg_manager.query_graph(start_node=test_kg_query_entity, relationship="treats")
",
    "        if kg_results:
",
    "            print(f"  '{test_kg_query_entity}' treats: {kg_results}")
",
    "        else:
",
    "            print(f"  No 'treats' relations found for '{test_kg_query_entity}'.")
",
    "
",
    "        # Visualize graph
",
    "        print(f"\nVisualizing graph and saving to '{KG_VISUALIZATION_PATH}'...")
",
    "        kg_manager.visualize_graph(output_file_path=KG_VISUALIZATION_PATH)
",
    "    else:
",
    "        print("\nKnowledge Graph is empty, skipping queries and visualization.")
",
    "except NameError as e:
",
    "    print(f"KnowledgeGraphManager not defined or error: {e}. Skipping KG creation.")
",
    "except Exception as e:
",
    "    print(f"An unexpected error occurred during KG processing: {e}")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Agent Initialization and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_agent, rag_agent, kg_agent_instance, wiki_agent = None, None, None, None
",
    "mock_llm = None # Placeholder for a real LLM, agents might use a mock if None
",
    "
",
    "try:
",
    "    # Initialize Agents
",
    "    classifier_agent = QueryClassifierAgent() # Basic version doesn't need LLM
",
    "    print("QueryClassifierAgent initialized.")
",
    "
",
    "    if vs_manager and vs_manager.vector_store:
",
    "        # Pass a mock LLM or None to RAGAgent if no real LLM is configured for notebook
",
    "        rag_agent = RAGAgent(vector_store_manager=vs_manager, llm=mock_llm)
",
    "        print("RAGAgent initialized.")
",
    "    else:
",
    "        print("Skipping RAGAgent initialization as vector store is not ready.")
",
    "
",
    "    if kg_manager and kg_manager.graph.number_of_nodes() > 0:
",
    "        kg_agent_instance = KGAgent(kg_manager=kg_manager, llm=mock_llm)
",
    "        print("KGAgent initialized.")
",
    "    else:
",
    "        print("Skipping KGAgent initialization as Knowledge Graph is not ready or empty.")
",
    "
",
    "    wiki_fallback_handler = WikipediaFallback(top_k_results=1, doc_content_chars_max=1500)
",
    "    wiki_agent = WikipediaAgent(wikipedia_search_handler=wiki_fallback_handler)
",
    "    print("WikipediaAgent initialized.")
",
    "
",
    "    # Test individual agents
",
    "    if classifier_agent:
",
    "        q_classify = "What is Type 2 Diabetes?"
",
    "        class_res = classifier_agent.query(q_classify)
",
    "        print(f"\nClassifier result for '{q_classify}': {class_res.get('answer')}")
",
    "
",
    "    if rag_agent:
",
    "        q_rag = "What are common symptoms of diabetes?"
",
    "        rag_res = rag_agent.query(q_rag)
",
    "        print(f"\nRAG Agent for '{q_rag}': Answer: {rag_res.get('answer', '')[:200]}... (Conf: {rag_res.get('confidence')}) Source: {rag_res.get('source')}")
",
    "
",
    "    if kg_agent_instance:
",
    "        q_kg = "Aspirin treats what?"
",
    "        kg_res = kg_agent_instance.query(q_kg)
",
    "        print(f"\nKG Agent for '{q_kg}': Answer: {kg_res.get('answer')} (Conf: {kg_res.get('confidence')}) Source: {kg_res.get('source')}")
",
    "
",
    "    if wiki_agent:
",
    "        q_wiki = "Tell me about the history of penicillin"
",
    "        wiki_res = wiki_agent.query(q_wiki)
",
    "        print(f"\nWikipedia Agent for '{q_wiki}': Answer: {wiki_res.get('answer', '')[:200]}... (Conf: {wiki_res.get('confidence')}) Source: {wiki_res.get('source')}")
",
    "
",
    "except NameError as e:
",
    "    print(f"One or more agent classes not defined: {e}. Skipping agent initialization and testing.")
",
    "except Exception as e:
",
    "    print(f"An error occurred during agent initialization or testing: {e}")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. MasterControlProgram (MCP) Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcp = None
",
    "try:
",
    "    if classifier_agent and rag_agent and kg_agent_instance and wiki_agent:
",
    "        mcp = MasterControlProgram(
",
    "            classifier_agent=classifier_agent,
",
    "            rag_agent=rag_agent,
",
    "            kg_agent=kg_agent_instance,
",
    "            wikipedia_agent=wiki_agent,
",
    "            confidence_threshold_rag=0.4, # Lower for testing with mock/simple agents
",
    "            confidence_threshold_kg=0.5,
",
    "            always_try_wikipedia_on_low_confidence=True
",
    "        )
",
    "        print("\nMasterControlProgram initialized.")
",
    "
",
    "        test_questions_mcp = [
",
    "            "What is Aspirin?", # Should be classified as RAG
",
    "            "What are the connections between Aspirin and Fever?", # Should be classified as KG
",
    "            "Tell me about Ibuprofen effects", # Should be RAG, then Wikipedia if RAG is low
",
    "            "What is the chemical formula for water?" # Likely low confidence from RAG/KG, then Wikipedia
",
    "        ]
",
    "
",
    "        for q_mcp in test_questions_mcp:
",
    "            print(f"\n--- MCP Query: '{q_mcp}' ---")
",
    "            mcp_response = mcp.handle_question(q_mcp)
",
    "            print(f"  Classification: {mcp_response.get('classification_used')}")
",
    "            print(f"  Final Answer: {mcp_response.get('answer', '')[:300]}...")
",
    "            print(f"  Chosen Agent: {mcp_response.get('agent_name')}, Confidence: {mcp_response.get('confidence')}")
",
    "            if mcp_response.get('agent_name') == 'WikipediaAgent':
",
    "                print(f"  Source (Wiki): {mcp_response.get('source')}")
",
    "    else:
",
    "        print("\nOne or more agents not initialized. Skipping MCP testing.")
",
    "except NameError as e:
",
    "    print(f"MasterControlProgram or agent classes not defined: {e}. Skipping MCP testing.")
",
    "except Exception as e:
",
    "    print(f"An error occurred during MCP testing: {e}")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Gradio UI Predefined Questions Test (Conceptual)
",
    "The Gradio UI will have 5 predefined questions. We can test the MCP with similar questions here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if mcp: # Check if MCP was initialized
",
    "    predefined_questions_for_gradio = [
",
    "        "What are the primary uses of metformin?", # Expect RAG
",
    "        "Show connections related to 'Diabetes Mellitus'.", # Expect KG
",
    "        "What is a common side effect of lisinopril?", # Expect RAG
",
    "        "Briefly explain what a 'placebo effect' is.", # Expect RAG/Wikipedia
",
    "        "Are there any known interactions between warfarin and vitamin K?" # Expect RAG or KG
",
    "    ]
",
    "    print("\n--- Testing MCP with Gradio Predefined Questions ---")
",
    "    for q_gradio in predefined_questions_for_gradio:
",
    "        print(f"\n--- Gradio-like Query: '{q_gradio}' ---")
",
    "        gradio_resp = mcp.handle_question(q_gradio)
",
    "        print(f"  Classification: {gradio_resp.get('classification_used')}")
",
    "        print(f"  Final Answer: {gradio_resp.get('answer', '')[:300]}...")
",
    "        print(f"  Chosen Agent: {gradio_resp.get('agent_name')}, Confidence: {gradio_resp.get('confidence')}")
",
    "else:
",
    "    print("\nMCP not initialized. Skipping Gradio predefined questions test.")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook End"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
